name: ML Model Training and Validation

on:
    push:
        branches: [main, develop]
        paths:
            - "MLProject/**"
            - "dataset_preprocessing/**"
            - ".github/workflows/**"
    pull_request:
        branches: [main]
    schedule:
        # Jalankan setiap hari jam 2 pagi UTC untuk re-training otomatis
        - cron: "0 2 * * *"
    workflow_dispatch:
        # Memungkinkan trigger manual

jobs:
    train-model:
        runs-on: ubuntu-latest

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Set up Python
              uses: actions/setup-python@v4
              with:
                  python-version: "3.9"

            - name: Cache pip dependencies
              uses: actions/cache@v4
              with:
                  path: ~/.cache/pip
                  key: ${{ runner.os }}-pip-${{ hashFiles('MLProject/conda.yaml') }}
                  restore-keys: |
                      ${{ runner.os }}-pip-

            - name: Install system dependencies
              run: |
                  sudo apt-get update
                  sudo apt-get install -y python3-dev

            - name: Install Python dependencies
              run: |
                  python -m pip install --upgrade pip
                  pip install mlflow>=2.0.0
                  pip install scikit-learn>=1.0.0
                  pip install pandas>=1.3.0
                  pip install numpy>=1.21.0
                  pip install matplotlib>=3.5.0
                  pip install seaborn>=0.11.0
                  pip install pathlib2

            - name: Verify installation
              run: |
                  python -c "import mlflow, sklearn, pandas, numpy, matplotlib, seaborn; print('All packages imported successfully')"
                  python --version
                  pip list

            - name: Run model training
              run: |
                  cd MLProject
                  python modelling.py --data ../dataset_preprocessing/diabetes_preprocessed.csv

            - name: Check model artifacts
              run: |
                  if [ -d "MLProject/mlruns" ]; then
                    echo "✅ MLflow artifacts created successfully"
                    find MLProject/mlruns -type f -name "*.pkl" -o -name "*.json" | head -10
                    ls -la MLProject/mlruns/
                  else
                    echo "❌ No MLflow artifacts found"
                    ls -la MLProject/
                    exit 1
                  fi

            - name: Upload MLflow artifacts
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: mlflow-artifacts
                  path: MLProject/mlruns/
                  retention-days: 30

            - name: Upload training logs
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: training-logs
                  path: |
                      MLProject/*.png
                      MLProject/*.log
                  retention-days: 7

            - name: Model validation
              run: |
                  cd MLProject
                  python -c "
                  import mlflow
                  import pandas as pd
                  import sys
                  import os

                  print('Starting model validation...')

                  # Set tracking URI
                  mlflow.set_tracking_uri('file:./mlruns')

                  try:
                      # Get latest run
                      experiment = mlflow.get_experiment_by_name('diabetes-basic')
                      if experiment is None:
                          print('❌ Experiment \"diabetes-basic\" not found')
                          # List all experiments
                          experiments = mlflow.search_experiments()
                          print('Available experiments:')
                          for exp in experiments:
                              print(f'  - {exp.name} (ID: {exp.experiment_id})')
                          sys.exit(1)
                      
                      print(f'Found experiment: {experiment.name} (ID: {experiment.experiment_id})')
                      
                      runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])
                      if runs.empty:
                          print('❌ No runs found in experiment')
                          sys.exit(1)
                          
                      print(f'Found {len(runs)} runs')
                      
                      # Get latest run (first row is most recent)
                      latest_run = runs.iloc[0]
                      
                      # Check if accuracy metric exists
                      if 'metrics.accuracy' not in latest_run or pd.isna(latest_run['metrics.accuracy']):
                          print('❌ Accuracy metric not found in latest run')
                          print('Available metrics:', [col for col in latest_run.index if col.startswith('metrics.')])
                          sys.exit(1)
                      
                      accuracy = float(latest_run['metrics.accuracy'])
                      
                      print(f'Latest run ID: {latest_run[\"run_id\"]}')
                      print(f'Model accuracy: {accuracy:.4f}')
                      
                      # Validation criteria
                      min_accuracy = 0.70
                      if accuracy >= min_accuracy:
                          print(f'✅ Model passed validation (accuracy {accuracy:.4f} >= {min_accuracy})')
                          print('Model is ready for deployment!')
                      else:
                          print(f'❌ Model failed validation (accuracy {accuracy:.4f} < {min_accuracy})')
                          print('Model needs improvement before deployment.')
                          sys.exit(1)
                          
                  except Exception as e:
                      print(f'❌ Error during validation: {str(e)}')
                      import traceback
                      traceback.print_exc()
                      sys.exit(1)
                  "

            - name: Generate summary report
              if: always()
              run: |
                  cd MLProject
                  echo "# ML Training Summary" > ../training_summary.md
                  echo "" >> ../training_summary.md
                  echo "## Training Results" >> ../training_summary.md
                  echo "- **Date**: $(date)" >> ../training_summary.md
                  echo "- **Commit**: ${{ github.sha }}" >> ../training_summary.md
                  echo "- **Branch**: ${{ github.ref_name }}" >> ../training_summary.md
                  echo "" >> ../training_summary.md

                  if [ -d "mlruns" ]; then
                    echo "- **Status**: ✅ Training completed successfully" >> ../training_summary.md
                    echo "- **Artifacts**: MLflow artifacts generated" >> ../training_summary.md
                  else
                    echo "- **Status**: ❌ Training failed" >> ../training_summary.md
                  fi

                  cat ../training_summary.md

            - name: Upload summary report
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: training-summary
                  path: training_summary.md
                  retention-days: 30

name: ML Model Training and Validation

on:
    push:
        branches: [main, develop]
        paths:
            - "MLProject/**"
            - "dataset_preprocessing/**"
            - ".github/workflows/**"
    pull_request:
        branches: [main]
    schedule:
        # Jalankan setiap hari jam 2 pagi UTC untuk re-training otomatis
        - cron: "0 2 * * *"
    workflow_dispatch:
        # Memungkinkan trigger manual

jobs:
    train-model:
        runs-on: ubuntu-latest

        steps:
            - name: Checkout code
              uses: actions/checkout@v4

            - name: Set up Python
              uses: actions/setup-python@v4
              with:
                  python-version: "3.9"

            - name: Cache pip dependencies
              uses: actions/cache@v4
              with:
                  path: ~/.cache/pip
                  key: ${{ runner.os }}-pip-${{ hashFiles('MLProject/conda.yaml') }}
                  restore-keys: |
                      ${{ runner.os }}-pip-

            - name: Install system dependencies
              run: |
                  sudo apt-get update
                  sudo apt-get install -y python3-dev

            - name: Install Python dependencies
              run: |
                  python -m pip install --upgrade pip
                  pip install mlflow>=2.0.0
                  pip install scikit-learn>=1.0.0
                  pip install pandas>=1.3.0
                  pip install numpy>=1.21.0
                  pip install matplotlib>=3.5.0
                  pip install seaborn>=0.11.0
                  pip install pathlib2

            - name: Verify installation
              run: |
                  python -c "import mlflow, sklearn, pandas, numpy, matplotlib, seaborn; print('‚úÖ All packages imported successfully!')"
                  python --version
                  pip list

            - name: Run model training
              run: |
                  cd MLProject
                  python modelling.py --data ../dataset_preprocessing/diabetes_preprocessed.csv

            - name: Check model artifacts
              run: |
                  if [ -d "MLProject/mlruns" ]; then
                    echo "‚úÖ MLflow artifacts created successfully"
                    find MLProject/mlruns -type f -name "*.pkl" -o -name "*.json" | head -10
                  else
                    echo "‚ùå No MLflow artifacts found"
                    ls -la MLProject/
                    exit 1
                  fi

            - name: Upload MLflow artifacts
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: mlflow-artifacts
                  path: MLProject/mlruns/
                  retention-days: 30

            - name: Upload training logs
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: training-logs
                  path: |
                      MLProject/*.png
                      MLProject/*.log
                  retention-days: 7

            - name: Model validation
              run: |
                  cd MLProject
                  python - <<'PYCODE'
                  import mlflow
                  import pandas as pd
                  import sys

                  print("üöÄ Starting model validation...")

                  mlflow.set_tracking_uri("file:./mlruns")

                  try:
                      experiment = mlflow.get_experiment_by_name("diabetes-basic")
                      if experiment is None:
                          print("‚ùå Experiment 'diabetes-basic' not found.")
                          sys.exit(1)

                      print(f"‚úÖ Found experiment: {experiment.name} (ID: {experiment.experiment_id})")

                      runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])
                      if runs.empty:
                          print("‚ùå No runs found in this experiment.")
                          sys.exit(1)

                      print(f"‚ÑπÔ∏è Found {len(runs)} runs in MLflow.")

                      latest_run = runs.iloc[0]

                      # Try to find the correct accuracy metric key
                      possible_metrics = [
                          "metrics.accuracy",
                          "metrics.training_accuracy_score",
                          "metrics.training_score"
                      ]

                      metric_found = None
                      for m in possible_metrics:
                          if m in latest_run and not pd.isna(latest_run[m]):
                              metric_found = m
                              break

                      if metric_found is None:
                          print("‚ùå Accuracy-like metric not found in latest run.")
                          print("Available metrics:")
                          for col in latest_run.index:
                              if col.startswith("metrics."):
                                  print(f"  - {col}")
                          sys.exit(1)

                      accuracy = float(latest_run[metric_found])
                      print(f"‚úÖ Using metric: {metric_found} = {accuracy:.4f}")

                      # Validation logic
                      min_accuracy = 0.70
                      if accuracy >= min_accuracy:
                          print(f"üéØ Model passed validation (accuracy {accuracy:.4f} >= {min_accuracy})")
                          print("‚úÖ Model is ready for deployment!")
                      else:
                          print(f"‚ö†Ô∏è Model failed validation (accuracy {accuracy:.4f} < {min_accuracy})")
                          print("‚ùå Model needs improvement before deployment.")
                          sys.exit(1)

                  except Exception as e:
                      print(f"‚ùå Error during validation: {e}")
                      import traceback
                      traceback.print_exc()
                      sys.exit(1)
                  PYCODE

            - name: Generate summary report
              if: always()
              run: |
                  cd MLProject
                  echo "# ML Training Summary" > ../training_summary.md
                  echo "" >> ../training_summary.md
                  echo "## Training Results" >> ../training_summary.md
                  echo "- **Date**: $(date)" >> ../training_summary.md
                  echo "- **Commit**: ${{ github.sha }}" >> ../training_summary.md
                  echo "- **Branch**: ${{ github.ref_name }}" >> ../training_summary.md
                  echo "" >> ../training_summary.md

                  if [ -d "mlruns" ]; then
                    echo "- **Status**: ‚úÖ Training completed successfully" >> ../training_summary.md
                    echo "- **Artifacts**: MLflow artifacts generated" >> ../training_summary.md
                  else
                    echo "- **Status**: ‚ùå Training failed" >> ../training_summary.md
                  fi

                  cat ../training_summary.md

            - name: Upload summary report
              uses: actions/upload-artifact@v4
              if: always()
              with:
                  name: training-summary
                  path: training_summary.md
                  retention-days: 30

            - name: Set MLflow Tracking URI
              run: echo "MLFLOW_TRACKING_URI=file:./mlruns" >> $GITHUB_ENV
